{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d8d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed empty file: ../data_scraped/samsung\\2025-04-14\\1886751850436931953.csv\n",
      "Removed empty file: ../data_scraped/samsung\\2025-04-14\\1894284344283599133.csv\n",
      "Removed empty file: ../data_scraped/samsung\\2025-04-14\\1897497432537358622.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "companies = ['samsung', 'apple', 'nintendo']\n",
    "\n",
    "# Loop through each company and remove empty files\n",
    "for company in companies:\n",
    "    company_path = os.path.join(base_dir, company)\n",
    "    \n",
    "    for date_folder in os.listdir(company_path):\n",
    "        date_path = os.path.join(company_path, date_folder)\n",
    "        \n",
    "        for csv_file in os.listdir(date_path):\n",
    "            if csv_file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(date_path, csv_file)\n",
    "                \n",
    "                # Check if the file is empty\n",
    "                if os.stat(file_path).st_size <= 2:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Removed empty file: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb52bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "\n",
    "base_dir = \"../data_scraped/\"\n",
    "companies = ['samsung', 'apple', 'nintendo']\n",
    "data = []\n",
    "\n",
    "for company in companies:\n",
    "    company_path = os.path.join(base_dir, company)\n",
    "    \n",
    "    for date_folder in os.listdir(company_path):\n",
    "        date_path = os.path.join(company_path, date_folder)\n",
    "        \n",
    "        for csv_file in os.listdir(date_path):\n",
    "            if csv_file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(date_path, csv_file)\n",
    "                df = pd.read_csv(file_path)\n",
    "                \n",
    "                if df.empty: continue\n",
    "\n",
    "                # Main tweet is first row\n",
    "                main_tweet = df.iloc[0]\n",
    "                comments = df.iloc[1:]\n",
    "\n",
    "                # Sentiment analysis\n",
    "                main_sentiment = TextBlob(str(main_tweet['text'])).sentiment.polarity\n",
    "                comment_sentiments = comments['text'].dropna().apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "                \n",
    "                avg_comment_sentiment = comment_sentiments.mean() if not comment_sentiments.empty else None\n",
    "                \n",
    "                data.append({\n",
    "                    \"tweet_id\": csv_file.replace(\".csv\", \"\"),\n",
    "                    \"company\": company,\n",
    "                    \"date\": date_folder,\n",
    "                    \"username\": main_tweet['username'],\n",
    "                    \"text\": main_tweet['text'],\n",
    "                    \"replies\": main_tweet['replies'],\n",
    "                    \"reposts\": main_tweet['reposts'],\n",
    "                    \"likes\": main_tweet['likes'],\n",
    "                    \"bookmarks\": main_tweet['bookmarks'],\n",
    "                    \"views\": main_tweet['views'],\n",
    "                    \"comment_count\": len(comments),\n",
    "                    \"total_engagement\": main_tweet['replies'] + main_tweet['likes'] + main_tweet['bookmarks'] + main_tweet['reposts'],\n",
    "                    \"main_sentiment\": main_sentiment,\n",
    "                    \"avg_comment_sentiment\": avg_comment_sentiment\n",
    "                })\n",
    "\n",
    "# Create final DataFrame\n",
    "final_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc0c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by username\n",
    "user_df = final_df.groupby(\"username\").agg({\n",
    "    \"text\": \"count\",\n",
    "    \"main_sentiment\": \"mean\",\n",
    "    \"likes\": \"sum\",\n",
    "    \"replies\": \"sum\",\n",
    "    \"bookmarks\": \"sum\",\n",
    "    \"company\": lambda x: x.mode()[0] if not x.mode().empty else None\n",
    "}).reset_index()\n",
    "\n",
    "user_df.columns = [\n",
    "    \"username\", \"total_comments\", \"avg_sentiment\", \n",
    "    \"total_likes\", \"total_replies\", \"total_bookmarks\", \"preferred_brand\"\n",
    "]\n",
    "\n",
    "# Create custom engagement score\n",
    "user_df[\"engagement_score\"] = user_df[\"total_likes\"] + user_df[\"total_replies\"] + user_df[\"total_bookmarks\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d402cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\"total_comments\", \"avg_sentiment\", \"total_likes\", \"total_replies\", \"total_bookmarks\", \"engagement_score\"]\n",
    "X = user_df[features]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8035b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
